{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c33f6a3-69f0-400d-813f-3889b1c08d2b",
      "metadata": {},
      "source": "<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(235, 249, 245, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/database.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Integrating pandas with SingleStoreDB</h1>\n    </div>\n</div>"
    },
    {
      "cell_type": "markdown",
      "id": "084012cb-df73-4887-a105-9d82e2755508",
      "metadata": {},
      "source": "This notebook will show how to move data from a pandas `DataFrame` into SingleStoreDB as well\nas downloading a SingleStoreDB query to a pandas `DataFrame`. It should be noted that this\nis only intended for relatively small data sets and to do processing that can't otherwise\nbe done in SingleStoreDB itself. Moving data to the client for processing should only be done\nwhen there is no other alternative in the database."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6f398e-e63c-4477-ab37-fbdcdd2d92f0",
      "metadata": {},
      "outputs": [],
      "source": "import ibis\nimport pandas as pd\nimport singlestoredb as s2\nimport sqlalchemy as sa"
    },
    {
      "cell_type": "markdown",
      "id": "3b83e421-0ae5-46b3-a64d-25d77de7da0c",
      "metadata": {},
      "source": "## Create a database\n\nWe need to create a database to work with in the following examples."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b0ca2e7-52ec-4d97-b3e6-31ee4a2bd466",
      "metadata": {},
      "outputs": [],
      "source": "%%sql\nDROP DATABASE IF EXISTS pandas_integration;\n\nCREATE DATABASE IF NOT EXISTS pandas_integration;"
    },
    {
      "cell_type": "markdown",
      "id": "641ab7fd-a344-42f0-9cd9-755056374581",
      "metadata": {},
      "source": "<div class=\"alert alert-block alert-warning\">\n    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n    <div>\n        <p><b>Action Required</b></p>\n        <p>Make sure to select the <tt>pandas_integration</tt> database from the drop-down menu at the top of this notebook.\n        It updates the <tt>connection_url</tt> to connect to that database.</p>\n    </div>\n</div>"
    },
    {
      "cell_type": "markdown",
      "id": "f094c4b2-dade-4432-9173-db590e7cb1dd",
      "metadata": {},
      "source": "## Database connections\n\nIn the notebooks environment, the connection string for the currently selected database is kept\nin the `connection_url` variable as well as the `SINGLESTOREDB_URL` environment variable.\nThe connection variables are accessed automatically within the SingleStoreDB Python packages\nso that you do not need connection parameters when connecting.\n\nIn the following sections, we will connect to SingleStoreDB using each of the packages and demonstrate\ntechniques for moving data between pandas and SingleStoreDB."
    },
    {
      "cell_type": "markdown",
      "id": "a6ffcb91-b70b-4175-bad7-7d087483e66b",
      "metadata": {},
      "source": "## The Iris data set\n\nWe'll be using the Iris data set for the following examples. This data set includes five columns: `sepal_length`,\n`sepal_width`, `petal_length`, `petal_width` and `class`."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68129a0f-7bb7-4c1b-bdab-dbb5c8cb43a3",
      "metadata": {},
      "outputs": [],
      "source": "iris = pd.read_csv('https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/'\n                   'master/notebooks/integrating-with-pandas/data/iris.csv')\niris"
    },
    {
      "cell_type": "markdown",
      "id": "ff5ef64c-1046-4db0-bb96-dd976c42db39",
      "metadata": {},
      "source": "As you can see below, the first four columns are floats and the last column is a string \n(represented as an `object` in `DataFrame`s). The `petal_width` column has 5 missing values."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22392542-a71a-484b-9a3a-7e767d3bad07",
      "metadata": {},
      "outputs": [],
      "source": "iris.info()"
    },
    {
      "cell_type": "markdown",
      "id": "8ea1fa0c-247e-4aaa-98a1-0980921fcaf7",
      "metadata": {},
      "source": "## Moving data between SingleStoreDB and pandas `DataFrame`s\n\nMoving data from pandas `DataFrame`s to SingleStoreDB tables can be done in various ways from Python and even \nfrom each of the packages described here. This reference is to show the best techniques when using each \npackage.\n\nIt should be noted that moving data back-and-forth between pandas and SingleStoreDB should only be done when\nabsolutely needed since this can be a major bottleneck when working with and analyzing data. The hope is that\nthe features of SingleStoreDB are sufficient enough to alleviate the need to do much processing (if any) on \nthe client machine."
    },
    {
      "cell_type": "markdown",
      "id": "6d88c47a-7416-4566-b026-3e232afa7bc7",
      "metadata": {},
      "source": "### SingleStoreDB Python\n\nThe core library is the SingleStoreDB Python package. This is the package that all other SingleStoreDB\npackages are built on. To connect, simply call the `connect` function."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a36c4a90-0aeb-402a-8454-764730ac4a08",
      "metadata": {},
      "outputs": [],
      "source": "s2_conn = s2.connect()"
    },
    {
      "cell_type": "markdown",
      "id": "9e54271f-e185-4965-bfaf-2639c304d503",
      "metadata": {},
      "source": "Since the core library is a fairly low-level interface to SingleStoreDB, most operations are done simply by sending\nSQL code."
    },
    {
      "cell_type": "markdown",
      "id": "46f57610-87bd-45c8-84bd-e77c9b313527",
      "metadata": {},
      "source": "#### Creating a table\n\nBecause we are using a low-level driver, creating a table is just done using SQL code. We'll use the information\nabout the data set above to construct a `CREATE TABLE` statement."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc666be-0ce7-46bb-9afe-19f3435f02ff",
      "metadata": {},
      "outputs": [],
      "source": "s2_cur = s2_conn.cursor()\ns2_cur.execute(r'''\n    CREATE TABLE IF NOT EXISTS iris (\n        sepal_length DOUBLE,\n        sepal_width DOUBLE,\n        petal_length DOUBLE,\n        petal_width DOUBLE,\n        class TEXT\n    )\n''')"
    },
    {
      "cell_type": "markdown",
      "id": "29c23826-1862-48ec-a837-a3e25ea52362",
      "metadata": {},
      "source": "#### Upload the data from a `DataFrame`\n\nNow that we have a table, we can populate it with data from the `DataFrame`. Again, we will use\nSQL statements to do this. The Python client can execute single SQL statements using the \n`execute` method as used above, but since we are uploading multiple rows of data it is better\nto use the `executemany` method since it is optimized for this purpose. "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7347b35-f82d-4bf4-bc7d-75a1ecd478e2",
      "metadata": {},
      "outputs": [],
      "source": "# Construct the list of column names\ncols = ', '.join(iris.columns)\n\n# Construct a list of value placeholders for the INSERT statement\nvalues = ', '.join(['%s'] * len(iris.columns))\n\n# Get data as a list of tuples (not including the index)\ndata = list(iris.itertuples(index=False))\n\n# Execute the INSERT statement\ns2_cur.executemany(f'INSERT INTO iris({cols}) VALUES ({values})', data)"
    },
    {
      "cell_type": "markdown",
      "id": "f4846819-8043-4917-8b37-20ed4b4ab7ab",
      "metadata": {},
      "source": "We can select a sample of the rows to see that the data is now in SingleStoreDB."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801a8262-375a-40fc-8b2c-c15a8cee61a7",
      "metadata": {},
      "outputs": [],
      "source": "s2_cur.execute('SELECT * FROM iris LIMIT 10')\nfor row in s2_cur:\n    print(row)"
    },
    {
      "cell_type": "markdown",
      "id": "ff3de53a-76a8-44f5-a999-364692df4601",
      "metadata": {},
      "source": "#### Downloading the data to a `DataFrame`\n\nWe can download the data to a pandas `DataFrame` simply by selecting all columns of data, \nfetching all of the rows, and passing them to the `DataFrame` constructor."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9bf4d0-72be-4f70-9efa-129b041acba6",
      "metadata": {},
      "outputs": [],
      "source": "s2_cur.execute('SELECT * FROM iris')\n\n# Use the `description` attribute to get the column names\nnames = [x[0] for x in s2_cur.description]\n\ns2_iris_df = pd.DataFrame(list(s2_cur), columns=names)\ns2_iris_df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2f9043-a940-43dc-974a-162e8bd2d576",
      "metadata": {},
      "outputs": [],
      "source": "s2_iris_df.info()"
    },
    {
      "cell_type": "markdown",
      "id": "809ccd96-f00b-49ff-b19c-48d9b85c7e3f",
      "metadata": {},
      "source": "Now that we have demonstrated uploading and downloading data from a pandas `DataFrame` using the\nSingleStoreDB Python client, we can drop the table and move on to SQLAlchemy."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef3cbb3-0f01-47c4-b27f-0dcf5729e7cd",
      "metadata": {},
      "outputs": [],
      "source": "s2_cur.execute('DROP TABLE IF EXISTS iris')"
    },
    {
      "cell_type": "markdown",
      "id": "75788e0a-df76-4be7-8ced-d01fdc37d7b6",
      "metadata": {},
      "source": "### SQLAlchemy\n\nIn addition to the core Python library, you can use SQLAlchemy to connect to SingleStoreDB. Typically, when \nusing SQLAlchemy, you would use the SQLAlchemy `create_engine` function to create an engine, then call `connect`\non the engine to create connections from a pool. The SingleStoreDB Python package also has a `create_engine`\nfunction that does the same thing, however, it extends the default ability by allow you to use the \n`SINGLESTOREDB_URL` environment variable as the connection string so that no parameters are needed for\n`create_engine` when used in the notebooks environment."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea6ac741-7c01-4b34-95c8-59d97db70cab",
      "metadata": {},
      "outputs": [],
      "source": "sa_eng = s2.create_engine()\nsa_conn = sa_eng.connect()"
    },
    {
      "cell_type": "markdown",
      "id": "a0f0463a-9796-4f23-8081-6589fce6463d",
      "metadata": {},
      "source": "#### Uploading the data from a `DataFrame`\n\nUploading data from a `DataFrame` using SQLAlchemy is much easier than the lower-level Python library.\nThe pandas library itself has the ability to communicate with SingleStoreDB using a SQLAlchemy connection.\nIn this case, the `DataFrame` can create the table and populate it in one step using the `to_sql` method.\nThe `to_sql` method has various options to modify its behavior [documented on the pandas web site](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2c953c-09b9-4aa9-b491-751929322c19",
      "metadata": {},
      "outputs": [],
      "source": "iris.to_sql('iris', con=sa_conn, index=False, if_exists='replace')"
    },
    {
      "cell_type": "markdown",
      "id": "e4574813-c134-4c0a-8915-94c0c466863f",
      "metadata": {},
      "source": "We can verify the data is in SingleStoreDB with a simple `SELECT` statement."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6068dabe-5347-4449-926d-f52c0fb58b13",
      "metadata": {},
      "outputs": [],
      "source": "for row in sa_conn.execute('SELECT * FROM iris LIMIT 10'):\n    print(row)"
    },
    {
      "cell_type": "markdown",
      "id": "75b0a1ee-8c21-4b8a-856e-643485661bdf",
      "metadata": {},
      "source": "It is also possible to use SQLAlchemy expressions to query the table rather than raw SQL strings."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e13489-3d70-48c1-b17b-baebb0d0543c",
      "metadata": {},
      "outputs": [],
      "source": "# Create a metadata object\nmeta = sa.MetaData(bind=sa_eng)\nsa.MetaData.reflect(meta)\n\n# Get the iris table from reflected data\nsa_iris = meta.tables['iris']\n\n# Query the iris table\nquery = sa.select(sa_iris).limit(10)\n\n# Print results\nfor row in sa_conn.execute(query):\n    print(row)"
    },
    {
      "cell_type": "markdown",
      "id": "0db80753-98a7-4748-83fe-1190cd04415f",
      "metadata": {},
      "source": "#### Downloading the data to a `DataFrame`\n\nDownloading data to a pandas `DataFrame` is very simple. The result of the `execute` method can \nbe passed directly to the pandas `DataFrame` constructor."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6053dcf8-8774-4e73-a5d7-2a86bb597569",
      "metadata": {},
      "outputs": [],
      "source": "# Reset query to not include the limit\nquery = sa.select(sa_iris)\n\nsa_iris_df = pd.DataFrame(sa_conn.execute(query))\nsa_iris_df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c2a5a7b-a00d-48b5-8e8b-b19e08d5d792",
      "metadata": {},
      "outputs": [],
      "source": "sa_iris_df.info()"
    },
    {
      "cell_type": "markdown",
      "id": "c1dd2d93-f330-4e3a-b39a-32accc3d1a60",
      "metadata": {},
      "source": "Now that we have demonstrated using SQLAlchemy to upload and download pandas `DataFrames` we can drop \nthe table and move on to Ibis."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65eb886b-cdb6-4dae-bfaf-57a03d23cd51",
      "metadata": {},
      "outputs": [],
      "source": "sa_iris.drop()"
    },
    {
      "cell_type": "markdown",
      "id": "5693eca8-fa3c-46ad-94fb-73d02ca50478",
      "metadata": {},
      "source": "### Ibis (SingleStoreDB DataFrame)\n\nThe Ibis package allows you to treat tables in SingleStoreDB as `DataFrames`. The `DataFrame` expressions\nare used to build lazy expressions which generate SQL statements that get submitted to SingleStoreDB\nonly when you want to see the results of a query. Ibis using SQLAlchemy connections behind-the-scenes."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686b8296-d50e-4a0b-b464-8b7807417f79",
      "metadata": {},
      "outputs": [],
      "source": "ibis_conn = ibis.singlestoredb.connect()"
    },
    {
      "cell_type": "markdown",
      "id": "254fd629-e321-434f-a257-ccc3874ac93b",
      "metadata": {},
      "source": "#### Uploading the data from a `DataFrame`\n\nIbis is intended for tight integration with pandas, so it is no surprise that uploading a \npandas `DataFrame` with Ibis is straight-forward. \n\nIf you are not familiar with Ibis, you may notice the `execute` call at the end of this cell.\nIbis creates expressions in memory on the client machine until a view of the data is \nexplicitly asked for. Once you explicitly ask for a query to be executed, it then generates\nand submits the SQL code for the expression behind-the-scenes.\n\nIn this case, the `ibis_iris` object is a `DataFrame`-like object that is lazily constructing\nthe requested expression until `execute` is called on it. In the case of this example, uploading\nand downloading "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca99ab2-bd93-41da-98f7-82c0d9934f43",
      "metadata": {},
      "outputs": [],
      "source": "ibis_iris = ibis_conn.create_table('iris', iris, force=True)\nibis_iris.limit(10).execute()"
    },
    {
      "cell_type": "markdown",
      "id": "125cc52e-37fe-4c9f-a573-c81f6363ff36",
      "metadata": {},
      "source": "One way to see the SQL that gets submitted during `execute` is to compile the expression\nand print it. Ibis also has a options to display SQL queries as they are submitted."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e4ccba-bec5-451c-9fd1-4b0ba87e5a74",
      "metadata": {},
      "outputs": [],
      "source": "print(ibis_iris.compile())"
    },
    {
      "cell_type": "markdown",
      "id": "11e9fa6e-bb62-488c-a530-835ebd41d323",
      "metadata": {},
      "source": "The information about the table can be retrieved much like in a local pandas `DataFrame`."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bfbb75b-ef83-4400-9909-348a12ac83cd",
      "metadata": {},
      "outputs": [],
      "source": "ibis_iris.info().execute()"
    },
    {
      "cell_type": "markdown",
      "id": "1bb2e364-b2c2-4c07-81ea-3e20dec1c723",
      "metadata": {},
      "source": "#### Downloading the data from a `DataFrame`\n\nThe output from evaluating Ibis expressions returns a `DataFrame`, so we have already demonstrated\ndownloading data, but here is the code again."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e14b01-9350-4560-81f9-cf68f4e105f5",
      "metadata": {},
      "outputs": [],
      "source": "ibis_iris_df = ibis_iris.execute()\nibis_iris_df"
    },
    {
      "cell_type": "markdown",
      "id": "ef002757-d84c-4da2-a61c-48c424569261",
      "metadata": {},
      "source": "We have demonstrated both uploading and downloading pandas `DataFrames` using Ibis, so \nwe can drop the table now."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e96373d5-651c-4047-bda7-3e49bf6edb7a",
      "metadata": {},
      "outputs": [],
      "source": "ibis_conn.drop_table('iris')"
    },
    {
      "cell_type": "markdown",
      "id": "6a832062-3934-4541-81b5-5c3cf0c117ac",
      "metadata": {},
      "source": "## Conclusion\n\nWe have shown how to upload and download data from a pandas `DataFrame` to and from SingleStoreDB\nusing the SingleStoreDB Python client, SQLAlchemy, and Ibis. These techniques should enable you to\nintegrate your pandas workflows with SingleStoreDB."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6f10e5-7605-485b-82f3-7a26a17ae912",
      "metadata": {},
      "outputs": [],
      "source": "%%sql\nDROP DATABASE IF EXISTS pandas_integration;"
    },
    {
      "cell_type": "markdown",
      "id": "dca02e68-11a8-46b9-b2eb-35f466d0c96e",
      "metadata": {},
      "source": "<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n    <div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>\n</div>"
    }
  ],
  "metadata": {
    "jupyterlab": {
      "notebooks": {
        "version_major": 6,
        "version_minor": 4
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
