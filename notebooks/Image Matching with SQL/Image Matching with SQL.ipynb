{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dff08daa-d4e7-4816-b8de-be40c86ec2b9",
      "metadata": {},
      "source": "<div style=\"background-color: #1B1A21; text-align: right; margin-bottom: -1px\">\n    <img src=\"https://raw.githubusercontent.com/singlestore-labs/notebook-picture/main/singlestore-banner.png\" style=\"padding: 0px; padding-right: 20px; margin: 0px; padding-top: 20px; height: 60px\"/>\n    <img src=\"https://raw.githubusercontent.com/singlestore-labs/notebook-picture/main/banner-colors.png\" style=\"width:100%; height: 50px; padding: 0px; margin: 0px; margin-bottom: -8px\"/>\n</div>"
    },
    {
      "cell_type": "markdown",
      "id": "7b2bd61f-bdc4-4aef-9ab3-feeb8a0138d3",
      "metadata": {},
      "source": "# Image Matching in SingleStoreDB with SQL\n\nSingleStoreDB can supercharge your apps with AI!\n\nIn this notebook, we’ll demonstrate how we use the [`dot_product`](https://docs.singlestore.com/db/v8.1/en/reference/sql-reference/vector-functions/dot_product.html) function (for cosine similarity) to find a matching image of a celebrity from among 7 thousand records in just 3 milliseconds!\n\nEfficient retrieval of high-dimensional vectors and handling of large-scale vector similarity matching workloads are made possible by SingleStore’s distributed architecture and efficient low-level execution. SingleStoreDB powers many AI applications including face matching, product photo matching, object recognition, text similarity matching, and sentiment analysis. "
    },
    {
      "cell_type": "markdown",
      "id": "b21735c2-31ad-4e38-9a5f-afae2c46de38",
      "metadata": {},
      "source": "<div style=\"text-align: center\">\n<img src=\"https://raw.githubusercontent.com/singlestore-labs/singlestoredb-samples/main/Tutorials/Face%20matching/pics/notebook%20picture.png\" width=\"500\"/>\n</div>"
    },
    {
      "cell_type": "markdown",
      "id": "facd7889-eaed-44f8-ba7c-ac852c26e9f3",
      "metadata": {},
      "source": "## 1. Create a workspace in your workspace group\n\nS-00 is sufficient.\n\n## 2. Create a Database named image_recognition\n\nThe code below will drop the current `image_recognition` database and create a fresh one."
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ee1fb52-14ee-48cc-880c-d525a7d84988",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T18:06:03.441378Z",
          "iopub.status.busy": "2023-06-23T18:06:03.441068Z",
          "iopub.status.idle": "2023-06-23T18:06:09.258089Z",
          "shell.execute_reply": "2023-06-23T18:06:09.257502Z",
          "shell.execute_reply.started": "2023-06-23T18:06:03.441356Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": ""
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "%%sql\nDROP DATABASE IF EXISTS image_recognition;\n\nCREATE DATABASE image_recognition;"
    },
    {
      "cell_type": "markdown",
      "id": "899100f0-bac6-4e56-a1e3-eaf5ba32d345",
      "metadata": {},
      "source": "## 3. Select the newly created `image_recognition` database\n\nThe notebook must have a database selected for the `%%sql` magic commands and SQLAlchemy connections\nto connect to the correct database. To do so, select the `image_recognition` database from the\ndrop-down menu at the top of this notebook.\n\n<img src=\"https://raw.githubusercontent.com/singlestore-labs/singlestoredb-samples/main/Tutorials/Face%20matching/pics/Use_Face_Matching_Database.png\" style=\"width: 500px; border: 1px solid darkorchid\">"
    },
    {
      "cell_type": "markdown",
      "id": "278053e8-7457-4655-a6fe-5c95ecb361de",
      "metadata": {},
      "source": "## 4. Install and import the following libraries\n\nThis will take approximately 40 seconds. We are using the `--quiet` option of `pip` here to keep\nthe log messages from filling the output. You can remove that option if you want to see\nthe installation process. \n\nYou may see messages printed about not being able to find cuda drivers or TensorRT. These can\nbe ignored."
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4a58d896-5ea9-4335-8cfe-18de418ba2de",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T18:06:15.575117Z",
          "iopub.status.busy": "2023-06-23T18:06:15.574691Z",
          "iopub.status.idle": "2023-06-23T18:07:07.340887Z",
          "shell.execute_reply": "2023-06-23T18:07:07.340328Z",
          "shell.execute_reply.started": "2023-06-23T18:06:15.575095Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "2023-06-23 18:07:05.668205: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2023-06-23 18:07:05.670152: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-06-23 18:07:05.706749: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-06-23 18:07:05.707418: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-06-23 18:07:06.330394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
        }
      ],
      "source": "!pip3 install boto3 matplotlib tensorflow opencv-python-headless --quiet\n\nimport json\nimport os\nimport random\nimport urllib.request\n\nimport boto3\nimport cv2\nimport botocore.exceptions\nimport ipywidgets as widgets\nimport tensorflow.compat.v1 as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport requests\nimport sqlalchemy as sa\nimport tensorflow.compat.v1 as tf\nfrom botocore import UNSIGNED\nfrom botocore.client import Config\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.disable_v2_behavior()"
    },
    {
      "cell_type": "markdown",
      "id": "3bb47d4f-d54d-4fcc-835e-6a5066fa84bc",
      "metadata": {},
      "source": "## 5. Create a table of images of people\n\nThe table will contain two columns: 1) the filename containing the image and 2) the vector embedding\nof the image as a blob containing an array of 32-bit floats."
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b115b516-df6d-4100-aacc-c49c50a91819",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T15:02:17.538148Z",
          "iopub.status.busy": "2023-06-23T15:02:17.537725Z",
          "iopub.status.idle": "2023-06-23T15:02:17.562782Z",
          "shell.execute_reply": "2023-06-23T15:02:17.562303Z",
          "shell.execute_reply.started": "2023-06-23T15:02:17.538127Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(pymysql.err.OperationalError) (1050, \"Forwarding Error (node-0396878f-700e-461b-9e63-36729a61ae3e-master-0.svc-0396878f-700e-461b-9e63-36729a61ae3e:3306): Table 'people' already exists\")\n[SQL: CREATE TABLE people (filename VARCHAR(255), vector BLOB, SHARD(filename));]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
        }
      ],
      "source": "%%sql\nCREATE TABLE people (\n    filename VARCHAR(255), \n    vector BLOB, \n    SHARD(filename)\n);"
    },
    {
      "cell_type": "markdown",
      "id": "41a990db-9e11-48e3-8011-8bd9770a27a2",
      "metadata": {},
      "source": "## 6. Import our sample dataset into the table\n\n**This dataset has 7000 vector embeddings of celebrities!**\n\nNote that we are using the `converters=` parameter of `pd.read_csv` to parse the text as a JSON array and convert it\nto a numpy array for the resulting DataFrame column."
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d1fb9284-f64e-49c3-acf8-d01f7a0d7e81",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T15:03:03.458351Z",
          "iopub.status.busy": "2023-06-23T15:03:03.458032Z",
          "iopub.status.idle": "2023-06-23T15:03:03.461359Z",
          "shell.execute_reply": "2023-06-23T15:03:03.460685Z",
          "shell.execute_reply.started": "2023-06-23T15:03:03.458332Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "url = 'https://raw.githubusercontent.com/singlestore-labs/singlestoredb-samples/main/' + \\\n      'Tutorials/Face%20matching/celebrity_data.sql'"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5fe33107-3e46-49f8-9450-4cac14501a34",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T15:03:32.557424Z",
          "iopub.status.busy": "2023-06-23T15:03:32.557124Z",
          "iopub.status.idle": "2023-06-23T15:03:34.114813Z",
          "shell.execute_reply": "2023-06-23T15:03:34.114275Z",
          "shell.execute_reply.started": "2023-06-23T15:03:32.557405Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": "7161"
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "def json_to_numpy_array(x: str | None) -> np.ndarray | None:\n    \"\"\"Convert JSON array string to numpy array.\"\"\"\n    return np.array(json.loads(x), dtype='f4') if x else None\n\n\n# Read data into DataFrame\ndf = pd.read_csv(url, sep='\"', usecols=[1, 3], names=['filename', 'vector'], \n                 converters=dict(vector=json_to_numpy_array))\n\n# Create database connection\ndb_connection = sa.create_engine(connection_url).connect()\n\n# Upload DataFrame\ndf.to_sql('people', con=db_connection, index=False, if_exists='append')"
    },
    {
      "cell_type": "markdown",
      "id": "168be056-17da-4f94-8252-3e5d79459a8b",
      "metadata": {},
      "source": "## 7. Run our image matching algorithm using just 2 lines of SQL\n\nIn this example, we use an image of Adam Sandler and find the 5 closest images in our database to it. We use the `dot_product` function to measure cosine_similarity of each vector in the database to the input image. "
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b26fd8fe-a90d-47c5-9cd1-63def15e2eac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T15:03:40.397220Z",
          "iopub.status.busy": "2023-06-23T15:03:40.396799Z",
          "iopub.status.idle": "2023-06-23T15:03:40.579357Z",
          "shell.execute_reply": "2023-06-23T15:03:40.578784Z",
          "shell.execute_reply.started": "2023-06-23T15:03:40.397201Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": "<table>\n    <thead>\n        <tr>\n            <th>filename</th>\n            <th>score</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Adam_Sandler/Adam_Sandler_0003.jpg</td>\n            <td>0.9999998807907104</td>\n        </tr>\n        <tr>\n            <td>Adam_Sandler/Adam_Sandler_0002.jpg</td>\n            <td>0.8312748670578003</td>\n        </tr>\n        <tr>\n            <td>Adam_Sandler/Adam_Sandler_0001.jpg</td>\n            <td>0.765850841999054</td>\n        </tr>\n        <tr>\n            <td>Ian_Thorpe/Ian_Thorpe_0002.jpg</td>\n            <td>0.597813069820404</td>\n        </tr>\n        <tr>\n            <td>Adam_Sandler/Adam_Sandler_0004.jpg</td>\n            <td>0.5422974824905396</td>\n        </tr>\n    </tbody>\n</table>",
            "text/plain": "+------------------------------------+--------------------+\n|              filename              |       score        |\n+------------------------------------+--------------------+\n| Adam_Sandler/Adam_Sandler_0003.jpg | 0.9999998807907104 |\n| Adam_Sandler/Adam_Sandler_0002.jpg | 0.8312748670578003 |\n| Adam_Sandler/Adam_Sandler_0001.jpg | 0.765850841999054  |\n|   Ian_Thorpe/Ian_Thorpe_0002.jpg   | 0.597813069820404  |\n| Adam_Sandler/Adam_Sandler_0004.jpg | 0.5422974824905396 |\n+------------------------------------+--------------------+"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "%%sql\nSET @v = (SELECT vector FROM people WHERE filename = \"Adam_Sandler/Adam_Sandler_0003.jpg\");\nSELECT filename, DOT_PRODUCT(vector, @v) AS score FROM people ORDER BY score DESC LIMIT 5;"
    },
    {
      "cell_type": "markdown",
      "id": "1d0606a8-6503-4522-8a85-6366263e4b5e",
      "metadata": {},
      "source": "## 8. Pick an image of a celebrity and see which images matched closest to it!\n\n1. Run the code cell\n2. Pick a celebrity picture\n3. Wait for the match!"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6b4d75e4-38b5-491d-a77c-35f949ef4ca4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T15:04:26.890120Z",
          "iopub.status.busy": "2023-06-23T15:04:26.889779Z",
          "iopub.status.idle": "2023-06-23T15:04:27.124585Z",
          "shell.execute_reply": "2023-06-23T15:04:27.124002Z",
          "shell.execute_reply.started": "2023-06-23T15:04:26.890096Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58278f7418084374b463872da8008efb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Dropdown(description='Select an Image:', layout=Layout(width='max-content'), options=('Aaron_Eckhart/Aaron_Eck…"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd231b10aa644ae1a365c9f4b481d3a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": "s3 = boto3.resource('s3', region_name='us-east-1', config=Config(signature_version=UNSIGNED))\nbucket = s3.Bucket('studiotutorials')\nprefix = 'face_matching/'\n\npeoplenames = %sql SELECT filename FROM people ORDER BY filename;\n\nnames = [x[0] for x in peoplenames]\n\nout = widgets.Output(layout={'border': '1px solid black'})\n\ndef on_value_change(change: widgets.Output) -> None:\n    \"\"\"Handle a value change event on a drop-down menu.\"\"\"\n    with out:\n        out.clear_output();\n        selected_name = change.new\n        countdb = %sql SELECT COUNT(*) FROM people WHERE filename = '{{selected_name}}';\n        \n        if int(countdb[-1][0]) > 0: \n            %sql SET @v = (SELECT vector FROM people WHERE filename = '{{selected_name}}');\n            result = %sql SELECT filename, DOT_PRODUCT(vector, @v) AS score FROM people ORDER BY score DESC LIMIT 5;\n            original = \"original.jpg\"\n            images = []\n            matches = []\n            try:\n                bucket.download_file(prefix + selected_name, original)\n                images.append(original)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Code'] == \"404\":\n                    bucket.download_file(prefix + \"error.jpg\", original)\n                else:\n                    raise\n            cnt = 0\n            for res in result:\n                print(res)\n                temp_file = \"match\" + str(cnt) + \".jpg\"\n                images.append(temp_file)\n                matches.append(res[1])\n                try:\n                    bucket.download_file(prefix + res[0], temp_file)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        bucket.download_file(prefix + \"error.jpg\", temp_file)\n                    else:\n                        raise\n                cnt += 1\n            fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(40, 40))\n            for i in range(6):\n                axes[i].imshow(plt.imread(images[i]))\n                axes[i].set_xticks([])\n                axes[i].set_yticks([])\n                axes[i].set_xlabel('')\n                axes[i].set_ylabel('')\n                if i == 0:\n                  axes[i].set_title(\"Original Image\", fontsize=14)\n                else:\n                  axes[i].set_title(\"Match \" + str(i) + \". Score: \" + str(matches[i-1]), fontsize=14)\n            plt.show()\n        else:\n              print(\"No match for this image as it was not inserted into the People Table\")\n\ndropdown = widgets.Dropdown(\n    options=names,\n    description='Select an Image:',\n    placeholder='Select an Image!',\n    style={'description_width': 'initial'},\n    layout={'width': 'max-content'}\n)\n\ndisplay(dropdown)\ndropdown.observe(on_value_change, names='value')\ndisplay(out)"
    },
    {
      "cell_type": "markdown",
      "id": "cea04465-6a69-42f1-8249-4c49488506f6",
      "metadata": {},
      "source": "## 9. See which celebrity you look most like! \n\nIn this step, you'll need to upload a picture of yourself.\nNote that your image MUST be at least 160x160 pixels. Head-shots and zoomed-in photos work better as we don't preprocess the image to just isolate the facial context! We only have 7,000 pictures so matching might be limited.\n\n1. Run the code cell\n2. Upload your picture\n3. Wait for the match!\n\n**A low score for matching is less than 0.6.**"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "985fdb94-38fd-42c9-aaff-16620db0e954",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-23T15:04:52.048607Z",
          "iopub.status.busy": "2023-06-23T15:04:52.048355Z",
          "iopub.status.idle": "2023-06-23T15:04:53.093184Z",
          "shell.execute_reply": "2023-06-23T15:04:53.092525Z",
          "shell.execute_reply.started": "2023-06-23T15:04:52.048589Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "668be60083134e65be606d9be6bbb27e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "FileUpload(value=(), description='Upload')"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3a86e5fa2f54d4393fe2d1e966c620c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": "def prewhiten(x: np.ndarray) -> np.ndarray:\n    \"\"\"Prewhiten image data.\"\"\"\n    mean = np.mean(x)\n    std = np.std(x)\n    std_adj = np.maximum(std, 1.0 / np.sqrt(x.size))\n    y = np.multiply(np.subtract(x, mean), 1 / std_adj)\n    return y\n\n\ndef crop(image: np.ndarray, random_crop: bool, image_size: int) -> np.ndarray:\n    \"\"\"Crop an image to a given size.\"\"\"\n    if image.shape[1] > image_size:\n        sz1 = int(image.shape[1] // 2)\n        sz2 = int(image_size // 2)\n        if random_crop:\n            diff = sz1 - sz2\n            (h, v) = (np.random.randint(-diff, diff + 1), np.random.randint(-diff, diff + 1))\n        else:\n            (h, v) = (0, 0)\n        image = image[(sz1 - sz2 + v):(sz1 + sz2 + v), (sz1 - sz2 + h):(sz1 + sz2 + h), :]\n    return image\n\n\ndef flip(image: np.ndarray, random_flip: bool) -> np.ndarray:\n    \"\"\"Flip the image data left-to-right.\"\"\"\n    if random_flip and np.random.choice([True, False]):\n        image = np.fliplr(image)\n    return image\n\n\ndef load_data(\n    image_paths: list[str],\n    do_random_crop: bool,\n    do_random_flip: bool,\n    image_size: int,\n    do_prewhiten: bool=True,\n) -> np.ndarray:\n    nrof_samples = len(image_paths)\n    images = np.zeros((nrof_samples, image_size, image_size, 3))\n    for i in range(nrof_samples):\n        img = cv2.imread(image_paths[i])\n        if do_prewhiten:\n            img = prewhiten(img)\n        img = crop(img, do_random_crop, image_size)\n        img = flip(img, do_random_flip)\n        images[i, :, :, :] = img\n    return images\n\n\nnew_out= widgets.Output(layout={'border': '1px solid black'})\n\ns3 = boto3.resource('s3', region_name='us-east-1', config=Config(signature_version=UNSIGNED))\nbucket = s3.Bucket('studiotutorials')\nprefix = 'face_matching/'\nnames=[]\n\nlocal_folder = './face_matching_models'\nif not os.path.exists(local_folder):\n    os.makedirs(local_folder)   \n\ns3 = boto3.client('s3', region_name='us-east-1', config=Config(signature_version=UNSIGNED))\ns3.download_file('studiotutorials', 'face_matching_models/20170512-110547.pb',\n                 os.path.join(local_folder, '20170512-110547.pb'))\npb_file_path = './face_matching_models/20170512-110547.pb'\n\n# Load the .pb file into a graph\nwith tf.io.gfile.GFile(pb_file_path, 'rb') as f:\n    graph_def = tf.compat.v1.GraphDef()\n    graph_def.ParseFromString(f.read())\n\n\ndef handle_upload(change: widgets.Output) -> None:        \n    with new_out:\n        new_out.clear_output();\n        new_file_name=''\n        \n        # Get the uploaded file\n        uploaded_file = change.new\n        if uploaded_file[0]['name'].lower().endswith(('.png', '.jpg', '.jpeg')):\n            # Do something with the uploaded file\n            file_name = uploaded_file[0]['name']\n            random_number = random.randint(1, 100000000)\n            new_file_name = f\"{file_name.split('.')[0]}_{random_number}.{file_name.split('.')[-1]}\"\n            file_content = uploaded_file[0]['content']\n            with open(new_file_name, 'wb') as f:\n                f.write(file_content)\n            with tf.compat.v1.Session() as sess:\n                sess.graph.as_default()\n                tf.import_graph_def(graph_def, name='')\n                images_placeholder = sess.graph.get_tensor_by_name(\"input:0\")\n                embeddings = sess.graph.get_tensor_by_name(\"embeddings:0\")\n                phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n                phase_train = False\n                img = load_data([new_file_name], False, False, 160)\n                feed_dict = {\n                    images_placeholder: img,         \n                    phase_train_placeholder: phase_train,\n                }\n                embeddings_ = sess.run(embeddings, feed_dict=feed_dict)\n                embeddings_list = [float(x) for x in embeddings_[0]]\n                embeddings_json = json.dumps(embeddings_list)\n                %sql insert into people values('{{new_file_name}}', json_array_pack_f32(\"{{embddings_json}}\"));\n        else:\n            print(\"Upload a .png, .jpg or .jpeg image\")\n        \n        num_matches = 5\n        countdb = %sql SELECT COUNT(*) FROM people WHERE filename = '{{new_file_name}}';\n\n        if int(countdb[-1][0]) > 0: \n            %sql SET @v = (SELECT vector FROM people WHERE filename = '{{new_file_name}}');\n            result = %sql SELECT filename, DOT_PRODUCT(vector, @v) AS score FROM people ORDER BY score DESC LIMIT 5;\n            images = []\n            matches = []\n            images.append(new_file_name)\n            cnt = 0\n            for res in result:\n                print(res)\n                if (cnt == 0):\n                    temp_file = new_file_name\n                else:\n                    temp_file = \"match\" + str(cnt) + \".jpg\"\n                    try:\n                        bucket.download_file(prefix + res[0], temp_file)\n                    except botocore.exceptions.ClientError as e:\n                        if e.response['Error']['Code'] == \"404\":\n                            bucket.download_file(prefix + \"error.jpg\", temp_file)\n                        else:\n                            raise\n                images.append(temp_file)\n                matches.append(res[1])\n                cnt += 1\n            fig, axes = plt.subplots(nrows=1, ncols=num_matches+1, figsize=(40, 40))\n            %sql DELETE FROM people WHERE filename = '{{new_file_name}}';\n            for i in range(num_matches+1):\n                axes[i].imshow(plt.imread(images[i]))\n                axes[i].set_xticks([])\n                axes[i].set_yticks([])\n                axes[i].set_xlabel('')\n                axes[i].set_ylabel('')\n                if i == 0:\n                  axes[i].set_title(\"Original Image\", fontsize=14)\n                else:\n                  axes[i].set_title(\"Match \" + str(i) + \". Score: \" + str(matches[i-1]), fontsize=14)\n            plt.show()\n        else:\n            print(\"No match for this image as it was not inserted into the People Database\")\n\nupload_button = widgets.FileUpload()\ndisplay(upload_button)\nupload_button.observe(handle_upload, names='value')\ndisplay(new_out)"
    },
    {
      "cell_type": "markdown",
      "id": "f3f3c685-0335-46e2-9a8d-e46ec296f074",
      "metadata": {},
      "source": "## 10. Clean up"
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "id": "51614d50-1e1f-4fe5-ab8d-09c804619edb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-22T19:56:51.239130Z",
          "iopub.status.busy": "2023-06-22T19:56:51.238898Z",
          "iopub.status.idle": "2023-06-22T19:56:52.237587Z",
          "shell.execute_reply": "2023-06-22T19:56:52.237047Z",
          "shell.execute_reply.started": "2023-06-22T19:56:51.239116Z"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": ""
          },
          "execution_count": 288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "%%sql\nDROP DATABASE image_recognition;"
    },
    {
      "cell_type": "markdown",
      "id": "83729541-f1c7-4d12-8162-e82a3ea991a1",
      "metadata": {},
      "source": "<img src=\"https://raw.githubusercontent.com/singlestore-labs/notebook-picture/main/banner-colors-reverse.png\" style=\"width: 100%; margin: 0; padding: 0\"/>"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d22f8579-a40d-4387-9f09-f1147b806e0b",
      "metadata": {},
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "singlestore_connection": {
      "connectionID": "34713c62-c91a-4c84-91b3-79dff7cd693a",
      "defaultDatabase": "image_recognition"
    },
    "singlestore_row_limit": 300
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
