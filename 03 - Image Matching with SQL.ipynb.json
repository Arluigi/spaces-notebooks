{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7b2bd61f-bdc4-4aef-9ab3-feeb8a0138d3",
      "metadata": {},
      "source": "## **Image Matching in SQL with SingleStoreDB**\n\nSingleStoreDB can supercharge your apps with AI!\n\nIn this notebook, we’ll demonstrate how we use the `dot_product` function (for cosine similarity) to find a matching image of a celebrity from among 7 thousand records in just 3 milliseconds!\n\nEfficient retrieval of high-dimensional vectors and handling of large-scale vector similarity matching workloads are made possible by SingleStore’s distributed architecture and efficient low-level execution. SingleStoreDB powers many AI applications including face matching, product photo matching, object recognition, text similarity matching, and sentiment analysis. "
    },
    {
      "cell_type": "markdown",
      "id": "b21735c2-31ad-4e38-9a5f-afae2c46de38",
      "metadata": {},
      "source": "<img src=https://raw.githubusercontent.com/singlestore-labs/singlestoredb-samples/main/Tutorials/Face%20matching/pics/notebook%20picture.png width=\"500\">"
    },
    {
      "cell_type": "markdown",
      "id": "facd7889-eaed-44f8-ba7c-ac852c26e9f3",
      "metadata": {},
      "source": "### Step 1: Create a workspace in your workspace group – S00 is enough.\n\n### Step 2: Create a Database named image_recognition using the SQL command below:"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0ee1fb52-14ee-48cc-880c-d525a7d84988",
      "metadata": {
        "execution": {},
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "%%sql\ncreate database image_recognition"
    },
    {
      "cell_type": "markdown",
      "id": "899100f0-bac6-4e56-a1e3-eaf5ba32d345",
      "metadata": {},
      "source": "### Step 3: In this notebook, select the newly created image_recognition database from the dropdown box above\n<img src=https://raw.githubusercontent.com/singlestore-labs/singlestoredb-samples/main/Tutorials/Face%20matching/pics/Use_Face_Matching_Database.png width=\"500\">"
    },
    {
      "cell_type": "markdown",
      "id": "278053e8-7457-4655-a6fe-5c95ecb361de",
      "metadata": {},
      "source": "### Step 4: Install and Import the following libraries into your python kernel:\nIt will take ~40 seconds"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "4a58d896-5ea9-4335-8cfe-18de418ba2de",
      "metadata": {
        "execution": {},
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "!pip3 install boto3 matplotlib tensorflow opencv-python-headless\nimport boto3, requests, json, os, cv2, random\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom botocore import UNSIGNED\nfrom botocore.client import Config\nimport botocore.exceptions\nimport urllib.request\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nimport numpy as np"
    },
    {
      "cell_type": "markdown",
      "id": "3bb47d4f-d54d-4fcc-835e-6a5066fa84bc",
      "metadata": {},
      "source": "### Step 5: Create a table named people of schema (filename, vector) in your database"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b115b516-df6d-4100-aacc-c49c50a91819",
      "metadata": {
        "execution": {},
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "%%sql\ncreate table people (filename varchar(255), vector blob, shard(filename))"
    },
    {
      "cell_type": "markdown",
      "id": "41a990db-9e11-48e3-8011-8bd9770a27a2",
      "metadata": {},
      "source": "### Step 6: Import our sample dataset into your table. This dataset has 7000 vector embeddings of celebrities!\nIt should take 1:30-2 minutes to load all the vectorized pictures depending on the region or cloud you are in"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5fe33107-3e46-49f8-9450-4cac14501a34",
      "metadata": {
        "execution": {},
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "url = 'https://raw.githubusercontent.com/singlestore-labs/singlestoredb-samples/main/Tutorials/Face%20matching/celebrity_data.sql'\nresponse = requests.get(url)\nsql_script = response.text\nnew_array = sql_script.split('\\n')\nfor i in new_array:\n    new_i = i.replace(', ', ',')\n    %sql $new_i"
    },
    {
      "cell_type": "markdown",
      "id": "168be056-17da-4f94-8252-3e5d79459a8b",
      "metadata": {},
      "source": "### Step 7: Run our image matching algorithm using just 2 lines of SQL. \nIn this example, we use an image of Adam Sandler and find the 5 closest images in our database to it. We use the `dot_product` function to measure cosine_similarity of each vector in the database to the input image. "
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b26fd8fe-a90d-47c5-9cd1-63def15e2eac",
      "metadata": {
        "execution": {},
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "%%sql\nset @v = (select vector from people where filename = \"Adam_Sandler/Adam_Sandler_0003.jpg\");\nselect filename, dot_product(vector, @v) as score from people order by score desc limit 5;"
    },
    {
      "cell_type": "markdown",
      "id": "1d0606a8-6503-4522-8a85-6366263e4b5e",
      "metadata": {},
      "source": "### Step 8: Use our visualizer to pick an image of a celebrity and see which images matched closest to it!! \n1. Run the notebook\n2. Pick an artist picture\n3. Wait for the match!"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6b4d75e4-38b5-491d-a77c-35f949ef4ca4",
      "metadata": {
        "execution": {},
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "s3 = boto3.resource('s3',region_name='us-east-1', config=Config(signature_version=UNSIGNED))\nbucket = s3.Bucket('studiotutorials')\nprefix = 'face_matching/'\nnames=[]\n\npeoplenames = %sql select filename from people order by filename;\nfor i in peoplenames:\n    names.append(i[0])\n\nout = widgets.Output(layout={'border':'1px solid black'})\n\ndef on_value_change(change):\n    with out:\n        out.clear_output();\n        selected_name = change.new\n        countdb = %sql select count(*) from people where filename = '{selected_name}';\n        for i in countdb:\n            x = i[0]\n        if (int(x) > 0): \n            %sql set @v = (select vector from people where filename = '{selected_name}');\n            result = %sql select filename, dot_product(vector, @v) as score from people order by score desc limit 5;\n            original = \"original.jpg\"\n            images = []\n            matches = []\n            try:\n                bucket.download_file(prefix + selected_name, original)\n                images.append(original)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Code'] == \"404\":\n                    bucket.download_file(prefix + \"error.jpg\", original)\n                else:\n                      raise\n            cnt = 0\n            for res in result:\n                print(res)\n                temp_file = \"match\" + str(cnt) + \".jpg\"\n                images.append(temp_file)\n                matches.append(res[1])\n                try:\n                    bucket.download_file(prefix + res[0], temp_file)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        bucket.download_file(prefix + \"error.jpg\", temp_file)\n                    else:\n                        raise\n                cnt += 1\n            fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(40, 40))\n            for i in range(6):\n                axes[i].imshow(plt.imread(images[i]))\n                axes[i].set_xticks([])\n                axes[i].set_yticks([])\n                axes[i].set_xlabel('')\n                axes[i].set_ylabel('')\n                if i == 0:\n                  axes[i].set_title(\"Original Image\", fontsize=14)\n                else:\n                  axes[i].set_title(\"Match \" + str(i) + \". Score: \" + str(matches[i-1]), fontsize=14)\n            plt.show()\n        else:\n              print(\"No match for this image as it was not inserted into the People Table\")\n\ndropdown = widgets.Dropdown(\n    options=names,\n    description='Select an Image:',\n    placeholder='Select an Image!',\n    style={'description_width': 'initial'},\n    layout={'width': 'max-content'}\n)\n\ndisplay(dropdown)\ndropdown.observe(on_value_change, names='value')\ndisplay(out)"
    },
    {
      "cell_type": "markdown",
      "id": "cea04465-6a69-42f1-8249-4c49488506f6",
      "metadata": {},
      "source": "### Step 9: Upload your image, run our image matching algorithm, and see which celebrity you look most like!! \nNote that your image MUST be at least 160x160 pixels. Head-shots and zoomed-in photos work better as we don't preprocess the image to just isolate the facial context!! (we only have 7,000 pictures so matching might be limited)\n1. Run the notebook\n2. Upload your picture\n3. Wait for the match!\n#### A low score for matching is less than 0.6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "985fdb94-38fd-42c9-aaff-16620db0e954",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "def prewhiten(x):\n    mean = np.mean(x)\n    std = np.std(x)\n    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n    return y\n\ndef crop(image, random_crop, image_size):\n    if image.shape[1]>image_size:\n        sz1 = int(image.shape[1]//2)\n        sz2 = int(image_size//2)\n        if random_crop:\n            diff = sz1-sz2\n            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n        else:\n            (h, v) = (0,0)\n        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n    return image\n\ndef flip(image, random_flip):\n    if random_flip and np.random.choice([True, False]):\n        image = np.fliplr(image)\n    return image\n\ndef load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n    nrof_samples = len(image_paths)\n    images = np.zeros((nrof_samples, image_size, image_size, 3))\n    for i in range(nrof_samples):\n        img = cv2.imread(image_paths[i])\n        if do_prewhiten:\n            img = prewhiten(img)\n        img = crop(img, do_random_crop, image_size)\n        img = flip(img, do_random_flip)\n        images[i,:,:,:] = img\n    return images\n\nnew_out= widgets.Output(layout={'border':'1px solid black'})\n\ns3 = boto3.resource('s3',region_name='us-east-1', config=Config(signature_version=UNSIGNED))\nbucket = s3.Bucket('studiotutorials')\nprefix = 'face_matching/'\nnames=[]\n\n\nlocal_folder = './face_matching_models'\nif not os.path.exists(local_folder):\n    os.makedirs(local_folder)   \ns3 = boto3.client('s3',region_name='us-east-1', config=Config(signature_version=UNSIGNED))\ns3.download_file('studiotutorials', 'face_matching_models/20170512-110547.pb', os.path.join(local_folder, '20170512-110547.pb'))\npb_file_path = './face_matching_models/20170512-110547.pb'\n\n# Load the .pb file into a graph\nwith tf.io.gfile.GFile(pb_file_path, 'rb') as f:\n    graph_def = tf.compat.v1.GraphDef()\n    graph_def.ParseFromString(f.read())\n\ndef handle_upload(change):        \n    with new_out:\n        new_out.clear_output();\n        new_file_name=''\n        # Get the uploaded file\n        uploaded_file = change.new\n        if uploaded_file[0]['name'].lower().endswith(('.png','.jpg','.jpeg')):\n            # Do something with the uploaded file\n            file_name = uploaded_file[0]['name']\n            random_number = random.randint(1, 100000000)\n            new_file_name = f\"{file_name.split('.')[0]}_{random_number}.png\"\n            file_content = uploaded_file[0]['content']\n            with open(new_file_name, 'wb') as f:\n                f.write(file_content)                \n                    \n            with tf.compat.v1.Session() as sess:\n                sess.graph.as_default()\n                tf.import_graph_def(graph_def, name='')\n                images_placeholder = sess.graph.get_tensor_by_name(\"input:0\")\n                embeddings = sess.graph.get_tensor_by_name(\"embeddings:0\")\n                phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n\n                phase_train = False\n                \n                img = load_data([new_file_name], False, False, 160)\n                \n                feed_dict = {images_placeholder: img,         \n                             phase_train_placeholder: phase_train\n                            }\n                embeddings_ = sess.run(embeddings, feed_dict=feed_dict)\n                embeddings_list = [float(x) for x in embeddings_[0]]\n                embeddings_json = json.dumps(embeddings_list)\n                embddings_json_new = embeddings_json.replace(', ',',')\n                %sql insert into people values('{new_file_name}', json_array_pack_F32(\"{embddings_json_new}\"));\n        else:\n            print(\"Upload a .png, .jpg or .jpeg image\")\n        \n        num_matches = 5\n        countdb = %sql select count(*) from people where filename = '{new_file_name}';\n        for i in countdb:\n            x = i[0]\n        if (int(x) > 0): \n            %sql set @v = (select vector from people where filename = '{new_file_name}');\n            result = %sql select filename, dot_product(vector, @v) as score from people order by score desc limit 5;\n            images = []\n            matches = []\n            images.append(new_file_name)\n            cnt = 0\n            for res in result:\n                print(res)\n                if (cnt == 0):\n                    temp_file = new_file_name\n                else:\n                    temp_file = \"match\" + str(cnt) + \".jpg\"\n                    try:\n                        bucket.download_file(prefix + res[0], temp_file)\n                    except botocore.exceptions.ClientError as e:\n                        if e.response['Error']['Code'] == \"404\":\n                            bucket.download_file(prefix + \"error.jpg\", temp_file)\n                        else:\n                            raise\n                images.append(temp_file)\n                matches.append(res[1])\n                cnt += 1\n            fig, axes = plt.subplots(nrows=1, ncols=num_matches+1, figsize=(40, 40))\n            %sql delete from people where filename = '{new_file_name}';\n            for i in range(num_matches+1):\n                axes[i].imshow(plt.imread(images[i]))\n                axes[i].set_xticks([])\n                axes[i].set_yticks([])\n                axes[i].set_xlabel('')\n                axes[i].set_ylabel('')\n                if i == 0:\n                  axes[i].set_title(\"Original Image\", fontsize=14)\n                else:\n                  axes[i].set_title(\"Match \" + str(i) + \". Score: \" + str(matches[i-1]), fontsize=14)\n            plt.show()\n        else:\n              print(\"No match for this image as it was not inserted into the People Database\")\n\nupload_button = widgets.FileUpload()\ndisplay(upload_button)\nupload_button.observe(handle_upload, names='value')\ndisplay(new_out)"
    },
    {
      "cell_type": "markdown",
      "id": "f3f3c685-0335-46e2-9a8d-e46ec296f074",
      "metadata": {},
      "source": "### Step 10: drop the image_recognition database if you don't need it anymore"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "51614d50-1e1f-4fe5-ab8d-09c804619edb",
      "metadata": {
        "execution": {},
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "%%sql\ndrop database image_recognition"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d881621a-02d7-489f-8429-942acd9e0dd6",
      "metadata": {},
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}